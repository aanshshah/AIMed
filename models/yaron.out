performing hyperparamter optimization step 0
{'n_estimators': 50} 0.740740588062375
performing hyperparamter optimization step 1
{'max_depth': 2, 'min_child_weight': 2} 0.7557653033792218
performing hyperparamter optimization step 2
{'gamma': 0.0} 0.7557653033792218
performing hyperparamter optimization step 3
{'colsample_bytree': 0.6, 'subsample': 0.5} 0.7625141620210838
performing hyperparamter optimization step 4
{'reg_alpha': 10} 0.7626328088424236
performing hyperparamter optimization step 4b
{'reg_alpha': 5.0} 0.7626328088424236

Parameter optimization finished!
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.6, gamma=0.0, learning_rate=0.1,
       max_delta_step=0, max_depth=2, min_child_weight=2, missing=None,
       n_estimators=50, n_jobs=1, nthread=4, objective='binary:logistic',
       random_state=0, reg_alpha=5.0, reg_lambda=1,
       scale_pos_weight=8.286036036036036, seed=1, silent=True,
       subsample=0.5)
              precision    recall  f1-score   support

           0       0.95      0.64      0.77     32191
           1       0.20      0.75      0.32      3885

   micro avg       0.66      0.66      0.66     36076
   macro avg       0.58      0.69      0.54     36076
weighted avg       0.87      0.66      0.72     36076

