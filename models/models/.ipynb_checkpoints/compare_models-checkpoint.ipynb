{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, average_precision_score\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import shap\n",
    "from keras.metrics import binary_accuracy\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = pd.read_csv('../clean_data/x_no_index.csv')\n",
    "annotations = pd.read_csv('../clean_data/y_more_no_df_clean.csv')\n",
    "# c = pd.read_csv('../clean_data/x_with_lace.csv')\n",
    "# print(c.shape)\n",
    "comments = pd.read_csv('../clean_data/x_with_lacefeatures.csv')\n",
    "comments = comments.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "# annotations = pd.read_csv('../clean_data/y_equal_yes.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(comments, annotations, test_size=.1)\n",
    "print(comments.shape, annotations.shape)\n",
    "print(list(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pr_curve(y_test, y_score):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(name, y_test, y_pred):\n",
    "    score = accuracy_score(y_test, y_pred.round())\n",
    "    cm = confusion_matrix(y_test, y_pred.round())\n",
    "    fig2=plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title = str(name)+': '+str(score)\n",
    "    plt.title(all_sample_title, size = 15);\n",
    "    plt.show()\n",
    "    fig2.savefig('figures/'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(2000,input_dim=67,activation='relu', name='dense_1'))\n",
    "# #     model.add(Dropout(0.8, name='dropout_1'))\n",
    "#     model.add(Dense(1,activation='relu', name='dense_2'))\n",
    "# #     model.add(Dropout(0.2, name='dropout_2'))\n",
    "# #     model.add(Dense(1,activation='relu', name='dense_3'))\n",
    "# #     model.add(Dropout(0.2, name='dropout_2'))\n",
    "# #     model.add(Dense(1,activation='relu', name='dense_3'))\n",
    "# #     model.add(Dense(1,activation='relu', name='dense_4'))\n",
    "# #     model.add(Dense(1,activation='relu', name='dense_5'))\n",
    "#     #need to optimize beta_1, beta_2, epsilon, decay, amsgrad\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,input_dim=70,activation='relu', name='dense_1'))\n",
    "#     model.add(Dense(300,input_dim=68,activation='relu', name='dense_2'))\n",
    "#     model.add(Dropout(0.2, name='dropout_1'))\n",
    "#     model.add(Dense(500,activation='relu', name='dense_2'))\n",
    "#     model.add(Dense(200,activation='relu', name='dense_3'))\n",
    "#     model.add(Dense(100,activation='relu', name='dense_4'))\n",
    "    model.add(Dense(1,activation='sigmoid', name='dense_5'))\n",
    "#     model.add(Dropout(0.2, name='dropout_2'))\n",
    "#     model.add(Dense(1,activation='relu', name='dense_3'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "earlystop = EarlyStopping(monitor='loss', min_delta=0.0001, patience=8, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "model = create_model()\n",
    "MODEL_NAME = 'Neural Network 1'\n",
    "clf = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=1, callbacks=callbacks_list)\n",
    "scaler = StandardScaler()\n",
    "pipeline = Pipeline([('preprocess',scaler), ('clf',clf)])\n",
    "history = pipeline.fit(x_train, y_train)\n",
    "y_score_nn = pipeline.predict(x_test)\n",
    "# history = clf.fit(x_train, y_train)\n",
    "# y_score_nn = clf.predict(x_test)\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score_nn.round())\n",
    "acc_score_rf = sklearn.metrics.accuracy_score(y_test, y_score_nn.round())\n",
    "create_confusion_matrix(MODEL_NAME, y_test, y_score_nn.round())\n",
    "print(model.summary())\n",
    "print(classification_report(y_test,y_score_nn.round())) \n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('Accuracy score: {0:0.2f}'.format(\n",
    "      acc_score_rf))\n",
    "from contextlib import redirect_stdout\n",
    "with open('NN_figures/MODEL_NAME.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='NN_figures/'+MODEL_NAME+'.png')\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Saving a model\n",
    "joblib.dump(pipeline, 'nn_even_labels_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f_wrapper(X):\n",
    "    return pipeline.predict(X).flatten()\n",
    "X_train_summary = shap.kmeans(x_train, 20)\n",
    "explainer = shap.KernelExplainer(f_wrapper, X_train_summary)\n",
    "x_train_sample = x_train.sample(20)\n",
    "x_test_sample = x_test.sample(20)\n",
    "shap.initjs()\n",
    "shap_values = explainer.shap_values(x_test_sample)\n",
    "shap.summary_plot(shap_values, x_train_sample, plot_type=\"bar\")\n",
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "# perm = PermutationImportance(clf, random_state=0).fit(x_train,y_train)\n",
    "# eli5.show_weights(perm, feature_names = comments.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, n_estimators=10)\n",
    "rf.fit(x_train, y_train)\n",
    "y_score_rf = rf.predict_proba(x_test)[:, 1]\n",
    "average_precision = average_precision_score(y_test, y_score_rf.round())\n",
    "acc_score_rf = sklearn.metrics.accuracy_score(y_test, y_score_rf.round())\n",
    "\n",
    "\n",
    "create_confusion_matrix('Random Forest', y_test, y_score_rf.round())\n",
    "print(classification_report(y_test,y_score_rf.round())) \n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('Accuracy score: {0:0.2f}'.format(\n",
    "      acc_score_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel='linear')  \n",
    "classifier.fit(x_train, y_train)  \n",
    "y_score_svm = classifier.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, y_score_svm)\n",
    "acc_score_svm = sklearn.metrics.accuracy_score(y_test, y_score_svm.round())\n",
    "\n",
    "create_confusion_matrix('SVM', y_test, y_score_svm.round())\n",
    "print(classification_report(y_test,y_score_svm.round()))\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('Accuracy score: {0:0.2f}'.format(\n",
    "      acc_score_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(penalty='l2', random_state=0)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_score_lr = logisticRegr.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, y_score_lr.round())\n",
    "acc_score_lr = sklearn.metrics.accuracy_score(y_test, y_score_lr.round())\n",
    "\n",
    "create_confusion_matrix('Logistic Regression', y_test, y_score_lr.round())\n",
    "print(classification_report(y_test,y_score_lr.round()))\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('Accuracy score: {0:0.2f}'.format(\n",
    "      acc_score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_score_nb = nb.predict_proba(x_test)[:,1]\n",
    "average_precision = average_precision_score(y_test, y_score_nb.round())\n",
    "acc_score_nb = sklearn.metrics.accuracy_score(y_test, y_score_nb.round())\n",
    "\n",
    "create_confusion_matrix('Naive Bayes', y_test, y_score_nb.round()) \n",
    "print(classification_report(y_test,y_score_nb.round()))\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('Accuracy score: {0:0.2f}'.format(\n",
    "      acc_score_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_score_lr)\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_score_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_score_svm)\n",
    "auc_svm = auc(fpr_svm, tpr_svm)\n",
    "fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, y_score_nb)\n",
    "auc_nb = auc(fpr_nb, tpr_nb)\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_test, y_score_nn)\n",
    "auc_nn = auc(fpr_nn, tpr_nn)\n",
    "fig=plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_lr, tpr_lr, label='LR (area = {:.3f})'.format(auc_lr))\n",
    "plt.plot(fpr_svm, tpr_svm, label='SVM (area = {:.3f})'.format(auc_svm))\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.plot(fpr_nb, tpr_nb, label='NB (area = {:.3f})'.format(auc_nb))\n",
    "plt.plot(fpr_nn, tpr_nn, label='NN (area = {:.3f})'.format(auc_nb))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "fig.savefig('figures/initial_ROC.png')\n",
    "plt.close()\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_score_lr)\n",
    "average_precision_lr = average_precision_score(y_test, y_score_lr)\n",
    "precision_nb, recall_nb, _ = precision_recall_curve(y_test, y_score_nb)\n",
    "average_precision_nb = average_precision_score(y_test, y_score_nb)\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_test, y_score_svm)\n",
    "average_precision_svm = average_precision_score(y_test, y_score_svm)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_score_rf)\n",
    "average_precision_rf = average_precision_score(y_test, y_score_rf)\n",
    "precision_nn, recall_nn, _ = precision_recall_curve(y_test, y_score_nn)\n",
    "average_precision_nn = average_precision_score(y_test, y_score_nn)\n",
    "\n",
    "plt.plot(recall_lr, precision_lr, label='LR (area = {:.3f})'.format(average_precision_lr))\n",
    "plt.plot(recall_svm, precision_svm, label='SVM (area = {:.3f})'.format(average_precision_svm))\n",
    "plt.plot(recall_rf, precision_rf, label='RF (area = {:.3f})'.format(average_precision_rf))\n",
    "plt.plot(recall_nb, precision_nb, label='NB (area = {:.3f})'.format(average_precision_nb))\n",
    "plt.plot(recall_nb, precision_nb, label='NN (area = {:.3f})'.format(average_precision_nn))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "fig.savefig('figures/PR_AUC.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
