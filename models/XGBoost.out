RUN_XGBOOST CLUSTER: 0
performing hyperparamter optimization step 0
{'n_estimators': 50} 0.7511280807296165
performing hyperparamter optimization step 1
{'max_depth': 2, 'min_child_weight': 3} 0.7906763525906301
performing hyperparamter optimization step 2
{'gamma': 0.0} 0.7906763525906301
performing hyperparamter optimization step 3
{'colsample_bytree': 0.8, 'subsample': 0.4} 0.7987558990114664
performing hyperparamter optimization step 4
{'reg_alpha': 0} 0.7987558990114664
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.8, gamma=0.0, learning_rate=0.1,
       max_delta_step=0, max_depth=2, min_child_weight=3, missing=None,
       n_estimators=50, n_jobs=1, nthread=4, objective='binary:logistic',
       random_state=0, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=10.186375321336762, seed=1, silent=True,
       subsample=0.4)
class weight scale : 10.198198198198199
class weight scale : 10.1994851994852
class weight scale : 10.186375321336762
class weight scale : 10.186375321336762
class weight scale : 10.186375321336762
Traceback (most recent call last):
  File "xg_boost_fit.py", line 256, in <module>
    run_xgboost()
  File "xg_boost_fit.py", line 110, in run_xgboost
    store_cluster_info(y_predications, y_real, name, cluster)
  File "xg_boost_fit.py", line 51, in store_cluster_info
    average_precision = average_precision_score(y_test, y_preds)
  File "/users/ashah3/scratch/env/lib/python3.6/site-packages/sklearn/metrics/ranking.py", line 241, in average_precision_score
    average, sample_weight=sample_weight)
  File "/users/ashah3/scratch/env/lib/python3.6/site-packages/sklearn/metrics/base.py", line 74, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: unknown format is not supported
