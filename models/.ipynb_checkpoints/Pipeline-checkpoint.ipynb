{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#supress warnings (especially from sklearn)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ccs_data = pd.read_csv('../data/patient_ccs_100.csv')\n",
    "ccs_data = ccs_data.rename(index=str, columns={\"SUBJECT_ID\": \"subject_id\", \"HADM_ID\": \"hadm_id\"})\n",
    "all_data = pd.read_csv('../data/x_with_lacefeatures.csv')\n",
    "labels = pd.read_csv('../data/y_more_no_df_clean.csv')\n",
    "merged_data = all_data.merge(ccs_data, on=['subject_id', 'hadm_id'])\n",
    "labeled_data = merged_data.join(labels)\n",
    "labeled_data.to_csv('../data/labeled_clustered_data_with_ids.csv')\n",
    "save_labeled_data = labeled_data.drop(['subject_id', 'hadm_id'], axis=1)\n",
    "save_labeled_data.to_csv('../data/labeled_clustered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_readmission = labeled_data.groupby(['cluster_num'])['label'].sum()\n",
    "cluster_readmission = cluster_readmission.reset_index(drop=False)\n",
    "total_noreadmit, total_readmit = labeled_data['label'].value_counts()\n",
    "sns.barplot(x='cluster_num', y='label', data=cluster_readmission)\n",
    "plt.title('Readmissions by Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_readmits = labeled_data['cluster_num'].value_counts()\n",
    "readmits = {}\n",
    "for cluster, readmit in enumerate(cluster_readmission['label']):\n",
    "    readmits[cluster] = float(readmit)/float(cluster_readmits[cluster])\n",
    "plt.bar(range(len(readmits)), list(readmits.values()), align='center')\n",
    "plt.xticks(range(len(readmits)), list(readmits.keys()))\n",
    "plt.ylabel('Percent readmitted')\n",
    "plt.xlabel('Cluster Number')\n",
    "plt.title('Percent readmitted by cluster (out of all patients in cluster)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readmits_all = {}\n",
    "readmits_r = {}\n",
    "for cluster, readmit in enumerate(cluster_readmission['label']):\n",
    "    readmits_all[cluster] = float(readmit)/float(total_noreadmit+total_readmit)\n",
    "    readmits_r[cluster] = float(readmit)/float(total_readmit)\n",
    "plt.bar(range(len(readmits_r)), list(readmits_r.values()), align='center')\n",
    "plt.xticks(range(len(readmits_r)), list(readmits_r.keys()))\n",
    "plt.ylabel('Percent readmitted')\n",
    "plt.xlabel('Cluster')\n",
    "plt.title('Percent readmitted in cluster out of all readmitted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    data = pd.read_csv('../data/labeled_clustered_data.csv')\n",
    "    df_0 = data[(data[['cluster_num']] == 0).any(axis=1)]\n",
    "    df_0_label=df_0.pop('label')\n",
    "    df_1 = data[(data[['cluster_num']] == 1).any(axis=1)]\n",
    "    df_1_label=df_1.pop('label')\n",
    "    df_2 = data[(data[['cluster_num']] == 2).any(axis=1)]\n",
    "    df_2_label=df_2.pop('label')\n",
    "    dfs = [df_0, df_1, df_2]\n",
    "    dfs_labels = [df_0_label, df_1_label, df_2_label]\n",
    "    return dfs, dfs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report, filename):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pca(df):\n",
    "    pca = PCA().fit(df)\n",
    "    variances = np.cumsum(pca.explained_variance_ratio_)\n",
    "    max_variance = -1\n",
    "    n_components = 0\n",
    "    for c in range(len(variances)):\n",
    "        if variances[c] < 1 and variances[c] >  max_variance: \n",
    "            max_variance = variances[c]\n",
    "            n_components = c\n",
    "    reduced_data = PCA(n_components=n_components).fit_transform(df) \n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "    pipeline = []\n",
    "    lr = LogisticRegressionCV(random_state = 0, n_jobs=-1)\n",
    "    en = ElasticNetCV(random_state = 0, n_jobs=-1)\n",
    "    rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    pipeline.append(['logistic_regression', lr]) \n",
    "    pipeline.append(['elastic_network', en]) \n",
    "    pipeline.append(['random_forest', rf])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(dfs, dfs_labels):\n",
    "    pipeline = create_pipeline()\n",
    "    for i, df in enumerate(dfs):\n",
    "        labels = dfs_labels[i]\n",
    "        reduced_df = run_pca(df)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduced_df, labels, test_size=0.2, random_state=0)\n",
    "        for name, clf in pipeline:\n",
    "#             print(name+'_cluster_'+str(i))\n",
    "            directory = 'results/'\n",
    "            filename = directory+name+'_cluster_'+str(i)+'.csv'\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_preds = [0 if x < 0.5 else 1 for x in clf.predict(X_test)]\n",
    "            report = classification_report(y_test, y_preds, target_names=['Not Readmitted', 'Readmitted'])\n",
    "            classifaction_report_csv(report, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs, dfs_labels = preprocess()\n",
    "run_pipeline(dfs, dfs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
