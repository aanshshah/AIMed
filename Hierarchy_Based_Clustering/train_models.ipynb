{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#supress warnings (especially from sklearn)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_curve, roc_curve, auc, precision_score, roc_curve, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from scipy import interp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_patient_preprocess(): \n",
    "    data = pd.read_csv('../data/labeled_clustered_data.csv')\n",
    "    df_0 = data.drop(['Unnamed: 0', 'Unnamed: 0_y', 'cluster_num', 'sapsii', 'sofa'], axis=1)\n",
    "    df_0_label=df_0.pop('label')\n",
    "    return [df_0], [df_0_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "    pipeline = []\n",
    "    lr = LogisticRegressionCV(random_state = 0, n_jobs=-1)\n",
    "    en = ElasticNetCV(random_state = 0, n_jobs=-1)\n",
    "    rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    pipeline.append(['logistic_regression', lr]) \n",
    "    pipeline.append(['random_forest', rf])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr_curve(pr_map, dimension_reduction=False):\n",
    "    for cluster, clf_map in pr_map.items():\n",
    "        fig=plt.figure()\n",
    "        if dimension_reduction:\n",
    "            plt.title('PR Curve for Cluster '+str(cluster))\n",
    "            filepath = 'results/figures/'+str(cluster)+'cluster_PR.png'\n",
    "        else:\n",
    "            plt.title('PR Curve for Cluster '+str(cluster)+' without PCA')\n",
    "            filepath = 'results/figures/'+str(cluster)+'cluster_PR_withoutPCA.png'\n",
    "        for name, values in clf_map.items():\n",
    "                average_precision = values[0]\n",
    "                precision = values[1]\n",
    "                recall = values[2]\n",
    "                plt.plot(recall, precision, label=name+' (area = {:.3f})'.format(average_precision))\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        fig.savefig(filepath)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgboost(optimize=True):\n",
    "    dfs, dfs_labels = preprocess()\n",
    "    filepath = 'results/figures/'\n",
    "    for cluster, x_df in enumerate(dfs):\n",
    "        y_df = dfs_labels[cluster]  \n",
    "        xg_opt = opt_xgboost(cluster, x_df, y_df, optimize)\n",
    "        K = 5\n",
    "        eval_size = int(np.round(1./K))\n",
    "        skf = StratifiedKFold(n_splits=K)\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        mean_tpr = 0.0\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        lw = 2\n",
    "        i = 0\n",
    "        roc_aucs_xgbopt = []\n",
    "        for train_indices, test_indices in skf.split(x_df, y_df):\n",
    "            X_train, y_train = x_df.iloc[train_indices], y_df.iloc[train_indices]\n",
    "            X_valid, y_valid = x_df.iloc[test_indices], y_df.iloc[test_indices]\n",
    "            class_weight_scale = 1.*y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "            print('class weight scale : {}'.format(class_weight_scale))\n",
    "            xgb_opt.set_params(**{'scale_pos_weight' : class_weight_scale})\n",
    "            xgb_opt.fit(X_train,y_train)\n",
    "            xgb_opt_pred_prob = xgb_opt.predict_proba(X_valid)\n",
    "            fpr, tpr, thresholds = precision_recall_curve(y_valid, xgb_opt_pred_prob[:, 1])\n",
    "            mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "            mean_tpr[0] = 0.0\n",
    "            roc_auc = average_precision_score(y_valid, xgb1_pred_prob[:, 1])\n",
    "            roc_aucs_xgbopt.append(roc_auc)\n",
    "            plt.plot(fpr, tpr, lw=2, label='PR fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',\n",
    "                     label='Luck')\n",
    "\n",
    "            mean_tpr /= K\n",
    "            mean_tpr[-1] = 1.0\n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',\n",
    "                     label='Mean PR (area = %0.2f)' % mean_auc, lw=lw)\n",
    "\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.ylim([-0.05, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('PR curve Cluster %d' % (cluster))\n",
    "            plt.legend(loc=\"lower right\")\n",
    "\n",
    "            fig.savefig(filepath+'PR_Curve_cluster_'+str(cluster)+'.png')\n",
    "            if optimize:\n",
    "\n",
    "                aucs = [np.mean(roc_aucs_xgb1),\n",
    "                        gsearch0.best_score_,\n",
    "                        gsearch1.best_score_,\n",
    "                        gsearch2.best_score_,\n",
    "                        gsearch3.best_score_,\n",
    "                        gsearch4.best_score_,\n",
    "                        np.mean(roc_aucs_xgbopt)]\n",
    "\n",
    "                fig = plt.figure(figsize=(4,4))\n",
    "                plt.scatter(np.arange(1,len(aucs)+1), aucs)\n",
    "                plt.plot(np.arange(1,len(aucs)+1), aucs)\n",
    "                plt.xlim([0.5, len(aucs)+0.5])\n",
    "                plt.ylim([0.99*aucs[0], 1.01*aucs[-1]])\n",
    "                plt.xlabel('Hyperparamter optimization step')\n",
    "                plt.ylabel('AUC')\n",
    "                plt.title('Hyperparameter optimization')\n",
    "                plt.grid()\n",
    "                fig.savefig(filepath+'_optimization_cluster_'+str(cluster)+'.png')\n",
    "        \n",
    "\n",
    "\n",
    "def opt_xgboost(cluster, x_df, y_df, optimize=True):\n",
    "    # Define the class weight scale (a hyperparameter) as the ration of negative labels to positive labels.\n",
    "    # This instructs the classifier to address the class imbalance.\n",
    "    class_weight_scale = 1.*y_df.value_counts()[0]/y_df.value_counts()[1]\n",
    "    filepath = 'results/figures/'\n",
    "    # Setting minimal required initial hyperparameters\n",
    "    param={\n",
    "        'objective':'binary:logistic',\n",
    "        'nthread':4,\n",
    "        'scale_pos_weight':class_weight_scale,\n",
    "        'seed' : 1   \n",
    "    }\n",
    "    xgb1 = XGBClassifier()\n",
    "    xgb1.set_params(**param)\n",
    "    K = 5\n",
    "    eval_size = int(np.round(1./K))\n",
    "    skf = StratifiedKFold(n_splits=K)\n",
    "\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    lw = 2\n",
    "    i = 0\n",
    "    roc_aucs_xgb1 = []\n",
    "    for train_indices, test_indices in skf.split(x_df, y_df):\n",
    "        X_train, y_train = x_df.iloc[train_indices], y_df.iloc[train_indices]\n",
    "        X_valid, y_valid = x_df.iloc[test_indices], y_df.iloc[test_indices]\n",
    "        class_weight_scale = 1.*y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "#         print 'class weight scale : {}'.format(class_weight_scale)\n",
    "        xgb1.set_params(**{'scale_pos_weight' : class_weight_scale})\n",
    "        xgb1.fit(X_train,y_train)\n",
    "        xgb1_pred_prob = xgb1.predict_proba(X_valid)\n",
    "        fpr, tpr, thresholds = precision_recall_curve(y_valid, xgb1_pred_prob[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = average_precision_score(y_valid, xgb1_pred_prob[:, 1])\n",
    "        roc_aucs_xgb1.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=2, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',\n",
    "             label='Luck')\n",
    "\n",
    "    mean_tpr /= K\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',\n",
    "             label='Mean PR (area = %0.2f)' % mean_auc, lw=lw)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Initial estimator PR curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    fig.savefig(filepath+'_cluster_'+str(cluster)+'_initial_PR_curve.png')\n",
    "    X_train = x_df\n",
    "    y_train = y_df\n",
    "\n",
    "    if optimize:\n",
    "\n",
    "        param_test0 = {\n",
    "         'n_estimators':range(50,250,10)\n",
    "        }\n",
    "        print('performing hyperparamter optimization step 0')\n",
    "        gsearch0 = GridSearchCV(estimator = xgb1, param_grid = param_test0, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "        gsearch0.fit(X_train,y_train)\n",
    "        print(gsearch0.best_params_, gsearch0.best_score_)\n",
    "\n",
    "        param_test1 = {\n",
    "         'max_depth':range(1,10),\n",
    "         'min_child_weight':range(1,10)\n",
    "        }\n",
    "        print('performing hyperparamter optimization step 1')\n",
    "        gsearch1 = GridSearchCV(estimator = gsearch0.best_estimator_,\n",
    "         param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "        gsearch1.fit(X_train,y_train)\n",
    "        print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "\n",
    "        max_d = gsearch1.best_params_['max_depth']\n",
    "        min_c = gsearch1.best_params_['min_child_weight']\n",
    "\n",
    "        param_test2 = {\n",
    "         'gamma':[i/10. for i in range(0,5)]\n",
    "        }\n",
    "        print('performing hyperparamter optimization step 2')\n",
    "        gsearch2 = GridSearchCV(estimator = gsearch1.best_estimator_, \n",
    "         param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "        gsearch2.fit(X_train,y_train)\n",
    "        print(gsearch2.best_params_, gsearch2.best_score_)\n",
    "\n",
    "        param_test3 = {\n",
    "            'subsample':[i/10.0 for i in range(1,10)],\n",
    "            'colsample_bytree':[i/10.0 for i in range(1,10)]\n",
    "        }\n",
    "        print('performing hyperparamter optimization step 3')\n",
    "        gsearch3 = GridSearchCV(estimator = gsearch2.best_estimator_, \n",
    "         param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "        gsearch3.fit(X_train,y_train)\n",
    "        print(gsearch3.best_params_, gsearch3.best_score_)\n",
    "\n",
    "        param_test4 = {\n",
    "            'reg_alpha':[0, 1e-5, 1e-3, 0.1, 10]\n",
    "        }\n",
    "        print('performing hyperparamter optimization step 4')\n",
    "        gsearch4 = GridSearchCV(estimator = gsearch3.best_estimator_, \n",
    "         param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "        gsearch4.fit(X_train,y_train)\n",
    "        print(gsearch4.best_params_, gsearch4.best_score_)\n",
    "\n",
    "        alpha = gsearch4.best_params_['reg_alpha']\n",
    "        if alpha != 0:\n",
    "            param_test4b = {\n",
    "                'reg_alpha':[0.1*alpha, 0.25*alpha, 0.5*alpha, alpha, 2.5*alpha, 5*alpha, 10*alpha]\n",
    "            }\n",
    "            print('performing hyperparamter optimization step 4b')\n",
    "            gsearch4b = GridSearchCV(estimator = gsearch4.best_estimator_, \n",
    "             param_grid = param_test4b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "            gsearch4b.fit(X_train,y_train)\n",
    "            print(gsearch4b.best_params_, gsearch4.best_score_)\n",
    "            print('\\nParameter optimization finished!')\n",
    "            xgb_opt = gsearch4b.best_estimator_\n",
    "            xgb_opt\n",
    "        else:\n",
    "            xgb_opt = gsearch4.best_estimator_\n",
    "            xgb_opt\n",
    "    else: \n",
    "        # Pre-optimized settings\n",
    "        xgb_opt = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "           gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "           min_child_weight=5, missing=None, n_estimators=70, nthread=4,\n",
    "           objective='binary:logistic', reg_alpha=25.0, reg_lambda=1,\n",
    "           scale_pos_weight=7.0909090909090908, seed=1, silent=True,\n",
    "           subsample=0.6)\n",
    "\n",
    "    print(xgb_opt)\n",
    "    return xgb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report, filename):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(dimension_reduction=True):\n",
    "    dfs, dfs_labels = preprocess()\n",
    "    pipeline = create_pipeline()\n",
    "    pr_map = {} #maps cluster to clf to avg_precision, precision, recall\n",
    "    for i, df in enumerate(dfs):\n",
    "        labels = dfs_labels[i]\n",
    "        if dimension_reduction:\n",
    "            reduced_df = run_pca(df)\n",
    "        else:\n",
    "            reduced_df = df\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduced_df, labels, test_size=0.2, random_state=0)\n",
    "        cluster_pr = pr_map.get(i, {})\n",
    "        for name, clf in pipeline:\n",
    "            directory = 'results/'\n",
    "            if dimension_reduction:\n",
    "                filename = directory+name+'_cluster_all.csv'\n",
    "            else:\n",
    "                filename = directory+name+'_cluster_all.csv'\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_preds = [0 if x < 0.5 else 1 for x in clf.predict(X_test)]\n",
    "            average_precision = average_precision_score(y_test, y_preds)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_preds)\n",
    "            cluster_pr[name] = [average_precision, precision, recall]\n",
    "            report = classification_report(y_test, y_preds, target_names=['Not Readmitted', 'Readmitted'])\n",
    "            classifaction_report_csv(report, filename)\n",
    "        pr_map[i] = cluster_pr\n",
    "    pr_curve(pr_map, dimension_reduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
